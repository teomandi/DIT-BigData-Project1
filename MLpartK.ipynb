{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "def evaluation(clf, clf_name, train, y):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train, y, test_size=.33)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    starting_tm = time.time()\n",
    "    y_pred = clf.predict(x_test)\n",
    "    \n",
    "    print(\"Classifier: \", clf_name)\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision: \", metrics.precision_score(y_test, y_pred))\n",
    "    print(\"Recall: \", metrics.recall_score(y_test, y_pred))\n",
    "    print(\"F1-Measure: \", metrics.f1_score(y_test, y_pred))\n",
    "    print(\"Execution time: \" + str(time.time() - starting_tm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def grid_evaluattion(clf, msg, X, y, tuned_parameters, scores):\n",
    "    print(msg)\n",
    "    \n",
    "    # Split the dataset in two equal parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)    \n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\\n\" % score)\n",
    "    \n",
    "        clf = GridSearchCV(clf, tuned_parameters, scoring=score)\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "        print(\"Best parameters set found on development set: \")\n",
    "        print(clf.best_params_)\n",
    "        print(\"\\nGrid scores on development set:\")\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "    \n",
    "        print(\"Detailed classification report:\\n\")\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\\n\")\n",
    "        \n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print() "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "jobs_df = pd.read_csv(\"fake_job_postings.csv\")\n",
    "jobs_df = jobs_df.fillna('')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "len 17880\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "y = jobs_df[\"fraudulent\"]\n",
    "train = jobs_df[\"description\"]\n",
    "\n",
    "print(\"len\", len(jobs_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K\n",
    "\n",
    "## Part 1\n",
    "**Approach:** Handling description using TF-IDF or CountVectorizer then train a **Random Forest** model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\nmd\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "def stemming_tokenizer(str_input):\n",
    "    stemmer = porter_stemmer\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/teomandi/anaconda3/envs/project1/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Vectorization took:  50.1855525970459\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "starting_tm = time.time()\n",
    "vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer)\n",
    "\n",
    "vtrain = vectorizer.fit_transform(train)\n",
    "print(\"Vectorization took: \", str(time.time()-starting_tm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. SGD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  SGD\n",
      "Accuracy:  0.9733943399423827\n",
      "Precision:  0.9923076923076923\n",
      "Recall:  0.45263157894736844\n",
      "F1-Measure:  0.6216867469879518\n",
      "Execution time: 0.013849258422851562\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(n_jobs=12, loss='hinge', max_iter=50000)\n",
    "evaluation(sgd, \"SGD\", vtrain, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  SVC\n",
      "Accuracy:  0.9542450432130147\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F1-Measure:  0.0\n",
      "Execution time: 4.327768325805664\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/teomandi/anaconda3/envs/project1/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "evaluation(svc, \"SVC\", vtrain, y)\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rf = RandomForestClassifier(n_estimators=660, n_jobs=4)\n",
    "# evaluation(rf, \"Random Forest\", vtrain, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Statistics of the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "All:  17880\n",
      "fraud 866  percent:  4.8434004474272925\n",
      "non fraud 17014  percent:  95.1565995525727\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"All: \", len(jobs_df))\n",
    "\n",
    "fraud = jobs_df[jobs_df.fraudulent == 1]\n",
    "print(\"fraud\", len(fraud), \" percent: \", len(fraud)/len(jobs_df)*100)\n",
    "\n",
    "non_fraud = jobs_df[jobs_df.fraudulent == 0]\n",
    "print(\"non fraud\", len(non_fraud), \" percent: \", len(non_fraud)/len(jobs_df)*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Undersampling\n",
    "Removing some of the non_fraudulent records in order to get a more realistic and balance dataset. Then evaluate again."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "fraud 866  percent:  33.33333333333333\n",
      "non fraud 2598  percent:  66.66666666666666\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "under_non_fraud = non_fraud.sample(len(fraud)*2)\n",
    "new_dataset = pd.concat([under_non_fraud, fraud]).sample(frac=1)\n",
    "\n",
    "# new statistics\n",
    "print(\"fraud\", len(fraud), \" percent: \", len(fraud)/len(new_dataset)*100)\n",
    "print(\"non fraud\", len(new_dataset), \" percent: \", len(under_non_fraud)/len(new_dataset)*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/teomandi/anaconda3/envs/project1/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Vectorization took:  7.019770860671997\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "new_y = new_dataset[\"fraudulent\"]\n",
    "new_train = new_dataset[\"description\"]\n",
    "\n",
    "starting_tm = time.time()\n",
    "new_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer)\n",
    "\n",
    "new_vtrain = new_vectorizer.fit_transform(new_train)\n",
    "print(\"Vectorization took: \", str(time.time()-starting_tm))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  SGD\n",
      "Accuracy:  0.8694638694638694\n",
      "Precision:  0.8534798534798534\n",
      "Recall:  0.7639344262295082\n",
      "F1-Measure:  0.8062283737024223\n",
      "Execution time: 0.007569789886474609\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# SGD again\n",
    "sgd = SGDClassifier(n_jobs=12, loss='hinge', max_iter=50000)\n",
    "evaluation(sgd, \"SGD\", new_vtrain, new_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  SVC\n",
      "Accuracy:  0.6771561771561772\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "F1-Measure:  0.0\n",
      "Execution time: 0.6439886093139648\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/teomandi/anaconda3/envs/project1/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# SVC again\n",
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "evaluation(svc, \"SVC\", new_vtrain, new_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Part 2\n",
    "# Features Engineering\n",
    "\n",
    "**Approach:** Feature extraction. Getting some feature from the **description** and using it with the rest of the columns."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "jobs_df = pd.read_csv(\"fake_job_postings.csv\")\n",
    "jobs_df = jobs_df.fillna('')\n",
    "\n",
    "y = jobs_df[\"fraudulent\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features Extraction for Description, Company Profile, Benefits, Requirements and Title\n",
    "- Length\n",
    "- Character length without spaces\n",
    "- Number of words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Description\n",
    "jobs_df['len_desc'] = jobs_df[\"description\"].apply(lambda x: len(str(x)))\n",
    "jobs_df['len_char_desc'] = jobs_df[\"description\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "jobs_df['len_word_desc'] = jobs_df[\"description\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "feats_desc = ['len_desc', 'len_char_desc', 'len_word_desc']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Title\n",
    "jobs_df['len_title'] = jobs_df[\"title\"].apply(lambda x: len(str(x)))\n",
    "jobs_df['len_char_title'] = jobs_df[\"title\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "jobs_df['len_word_title'] = jobs_df[\"title\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "feats_title = ['len_title', 'len_char_title', 'len_word_title']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Company Profile\n",
    "jobs_df['len_cp'] = jobs_df[\"company_profile\"].apply(lambda x: len(str(x)))\n",
    "jobs_df['len_char_cp'] = jobs_df[\"company_profile\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "jobs_df['len_word_cp'] = jobs_df[\"company_profile\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "feats_cp = ['len_cp', 'len_char_cp', 'len_word_cp']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Benefits\n",
    "jobs_df['len_ben'] = jobs_df[\"benefits\"].apply(lambda x: len(str(x)))\n",
    "jobs_df['len_char_ben'] = jobs_df[\"benefits\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "jobs_df['len_word_ben'] = jobs_df[\"benefits\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "feats_ben = ['len_ben', 'len_char_ben', 'len_word_ben']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Requirements\n",
    "jobs_df['len_req'] = jobs_df[\"requirements\"].apply(lambda x: len(str(x)))\n",
    "jobs_df['len_char_req'] = jobs_df[\"requirements\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "jobs_df['len_word_req'] = jobs_df[\"requirements\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "feats_req = ['len_req', 'len_char_req', 'len_word_req']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Binary features will be as they are.\n",
    "Those are: telecommuting, has_company_logo, has_questions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "feats_bin = ['telecommuting', 'has_company_logo', 'has_questions']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature extraction for Salary Range\n",
    "- Minimum\n",
    "- Maximum\n",
    "- Difference"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_max(r):\n",
    "    if r!= \"\":\n",
    "        if \"-\" in r:\n",
    "            if r.split(\"-\")[1].isnumeric():\n",
    "                return int(r.split(\"-\")[1])\n",
    "            else:\n",
    "                return -1\n",
    "        else:\n",
    "            return int(r)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def get_diff(r):\n",
    "    if r!= \"\":\n",
    "        if \"-\" in r:\n",
    "            if r.split(\"-\")[0].isnumeric() and r.split(\"-\")[1].isnumeric():\n",
    "                return int(r.split(\"-\")[1]) - int(r.split(\"-\")[0])\n",
    "            else:\n",
    "                return -1\n",
    "        else:\n",
    "            return int(r)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "jobs_df['min_salary'] = jobs_df[\"salary_range\"].apply(lambda r: int(r.split(\"-\")[0]) if r.split(\"-\")[0].isnumeric() else -1 if \"-\" in r else r if r != '' else -1)\n",
    "jobs_df['max_salary'] = jobs_df[\"salary_range\"].apply(get_max)\n",
    "jobs_df['diff_salary'] = jobs_df[\"salary_range\"].apply(get_diff)\n",
    "\n",
    "feats_salary = ['min_salary', 'max_salary', 'diff_salary']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Columns with simple text(few words) that are repeated get as feature an id. Same texts will get the same id\n",
    "Simple class used: Dictionary\n",
    "\n",
    "Those are: location, department, employment_type, required_experience, required_education, industry, function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class Dictionary:    \n",
    "    def __init__(self):\n",
    "        self.dic = {}\n",
    "        self.id = 0\n",
    "    \n",
    "    def add_to_dict(self, text):\n",
    "        text = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", text).lower() \n",
    "        if text in self.dic:\n",
    "            return self.dic[text]\n",
    "        else:\n",
    "            self.dic[text] = int(self.id)\n",
    "            self.id += 1\n",
    "            return self.dic[text]\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "location_dict = Dictionary()\n",
    "jobs_df['loc_ids'] = jobs_df['location'].apply(location_dict.add_to_dict)\n",
    "\n",
    "department_dict = Dictionary()\n",
    "jobs_df['dep_ids'] = jobs_df['department'].apply(department_dict.add_to_dict)\n",
    "\n",
    "employment_type_dict = Dictionary()\n",
    "jobs_df['emptype_ids'] = jobs_df['employment_type'].apply(employment_type_dict.add_to_dict)\n",
    "\n",
    "required_experience_dict = Dictionary()\n",
    "jobs_df['reqexp_ids'] = jobs_df['required_experience'].apply(required_experience_dict.add_to_dict)\n",
    "\n",
    "required_education_dict = Dictionary()\n",
    "jobs_df['reqedu_ids'] = jobs_df['required_education'].apply(required_education_dict.add_to_dict)\n",
    "\n",
    "industry_dict = Dictionary()\n",
    "jobs_df['ind_ids'] = jobs_df['industry'].apply(industry_dict.add_to_dict)\n",
    "\n",
    "function_dict = Dictionary()\n",
    "jobs_df['func_ids'] = jobs_df['function'].apply(function_dict.add_to_dict)\n",
    "\n",
    "reptext_feat = ['loc_ids', 'dep_ids', 'emptype_ids', 'reqexp_ids', 'reqedu_ids', 'ind_ids', 'func_ids']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "   len_desc  len_char_desc  len_word_desc  len_title  len_char_title  \\\n0       905             46            124         16              10   \n1      2077             71            315         41              18   \n2       355             31             50         39              18   \n3      2600             58            346         33              19   \n4      1520             59            168         19              12   \n\n   len_word_title  len_cp  len_char_cp  len_word_cp  len_ben  ...  min_salary  \\\n0               2     885           46          141        0  ...          -1   \n1               6    1286           58          153     1292  ...          -1   \n2               4     879           44          141        0  ...          -1   \n3               5     614           43           85      782  ...          -1   \n4               3    1628           68          207       21  ...          -1   \n\n   max_salary  diff_salary  loc_ids  dep_ids  emptype_ids  reqexp_ids  \\\n0          -1           -1        0        0            0           0   \n1          -1           -1        1        1            1           1   \n2          -1           -1        2        2            2           2   \n3          -1           -1        3        3            1           3   \n4          -1           -1        4        2            1           3   \n\n   reqedu_ids  ind_ids  func_ids  \n0           0        0         0  \n1           0        1         1  \n2           0        0         2  \n3           1        2         3  \n4           1        3         4  \n\n[5 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>len_desc</th>\n      <th>len_char_desc</th>\n      <th>len_word_desc</th>\n      <th>len_title</th>\n      <th>len_char_title</th>\n      <th>len_word_title</th>\n      <th>len_cp</th>\n      <th>len_char_cp</th>\n      <th>len_word_cp</th>\n      <th>len_ben</th>\n      <th>...</th>\n      <th>min_salary</th>\n      <th>max_salary</th>\n      <th>diff_salary</th>\n      <th>loc_ids</th>\n      <th>dep_ids</th>\n      <th>emptype_ids</th>\n      <th>reqexp_ids</th>\n      <th>reqedu_ids</th>\n      <th>ind_ids</th>\n      <th>func_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>905</td>\n      <td>46</td>\n      <td>124</td>\n      <td>16</td>\n      <td>10</td>\n      <td>2</td>\n      <td>885</td>\n      <td>46</td>\n      <td>141</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2077</td>\n      <td>71</td>\n      <td>315</td>\n      <td>41</td>\n      <td>18</td>\n      <td>6</td>\n      <td>1286</td>\n      <td>58</td>\n      <td>153</td>\n      <td>1292</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>355</td>\n      <td>31</td>\n      <td>50</td>\n      <td>39</td>\n      <td>18</td>\n      <td>4</td>\n      <td>879</td>\n      <td>44</td>\n      <td>141</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2600</td>\n      <td>58</td>\n      <td>346</td>\n      <td>33</td>\n      <td>19</td>\n      <td>5</td>\n      <td>614</td>\n      <td>43</td>\n      <td>85</td>\n      <td>782</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1520</td>\n      <td>59</td>\n      <td>168</td>\n      <td>19</td>\n      <td>12</td>\n      <td>3</td>\n      <td>1628</td>\n      <td>68</td>\n      <td>207</td>\n      <td>21</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 25
    }
   ],
   "source": [
    "feat_train = jobs_df[\n",
    "    feats_desc + feats_title + feats_cp +\n",
    "    feats_ben + feats_req + feats_bin +\n",
    "    feats_salary + reptext_feat\n",
    "]\n",
    "\n",
    "feat_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. SGD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  SGD\n",
      "Accuracy:  0.8505338078291815\n",
      "Precision:  0.07539118065433854\n",
      "Recall:  0.18596491228070175\n",
      "F1-Measure:  0.10728744939271254\n",
      "Execution time: 0.017270565032958984\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sgd = SGDClassifier(n_jobs=12, loss='hinge', max_iter=50000)\n",
    "evaluation(sgd, \"SGD\", feat_train, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  SVC\n",
      "Accuracy:  0.9556007456363328\n",
      "Precision:  1.0\n",
      "Recall:  0.050724637681159424\n",
      "F1-Measure:  0.09655172413793105\n",
      "Execution time: 2.5792479515075684\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "evaluation(svc, \"SVC\", feat_train, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Decision Tree Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  Decision Tree Classifier\n",
      "Accuracy:  0.9666158278257923\n",
      "Precision:  0.5980707395498392\n",
      "Recall:  0.7209302325581395\n",
      "F1-Measure:  0.6537785588752196\n",
      "Execution time: 0.008412599563598633\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dc = DecisionTreeClassifier()\n",
    "evaluation(dc, \"Decision Tree Classifier\", feat_train, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Bagging Classifier \n",
    "\n",
    "using 20 Decission Tress"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  Bagging Classifier\n",
      "Accuracy:  0.9778003728181665\n",
      "Precision:  0.9324324324324325\n",
      "Recall:  0.5328185328185329\n",
      "F1-Measure:  0.6781326781326782\n",
      "Execution time: 0.025699377059936523\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=1.0, n_estimators=20)\n",
    "evaluation(bagging, \"Bagging Classifier\", feat_train, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Voting Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  Voting Classifier\n",
      "Accuracy:  0.9533977291984409\n",
      "Precision:  0.7272727272727273\n",
      "Recall:  0.08275862068965517\n",
      "F1-Measure:  0.14860681114551083\n",
      "Execution time: 2.434481143951416\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sgd = SGDClassifier(n_jobs=12, loss='hinge', max_iter=50000)\n",
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "dc = DecisionTreeClassifier()\n",
    "\n",
    "voting = VotingClassifier(estimators=[('sgd',sgd),('svc',svc),('dc',dc)], voting='hard')\n",
    "evaluation(voting, \"Voting Classifier\", feat_train, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Reusing undersampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "new_dataset['len_desc'] = new_dataset[\"description\"].apply(lambda x: len(str(x)))\n",
    "new_dataset['len_char_desc'] = new_dataset[\"description\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "new_dataset['len_word_desc'] = new_dataset[\"description\"].apply(lambda x: len(str(x).split()))\n",
    "new_dataset['len_title'] = new_dataset[\"title\"].apply(lambda x: len(str(x)))\n",
    "new_dataset['len_char_title'] = new_dataset[\"title\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "new_dataset['len_word_title'] = new_dataset[\"title\"].apply(lambda x: len(str(x).split()))\n",
    "new_dataset['len_cp'] = new_dataset[\"company_profile\"].apply(lambda x: len(str(x)))\n",
    "new_dataset['len_char_cp'] = new_dataset[\"company_profile\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "new_dataset['len_word_cp'] = new_dataset[\"company_profile\"].apply(lambda x: len(str(x).split()))\n",
    "new_dataset['len_ben'] = new_dataset[\"benefits\"].apply(lambda x: len(str(x)))\n",
    "new_dataset['len_char_ben'] = new_dataset[\"benefits\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "new_dataset['len_word_ben'] = new_dataset[\"benefits\"].apply(lambda x: len(str(x).split()))\n",
    "new_dataset['len_req'] = new_dataset[\"requirements\"].apply(lambda x: len(str(x)))\n",
    "new_dataset['len_char_req'] = new_dataset[\"requirements\"].apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "new_dataset['len_word_req'] = new_dataset[\"requirements\"].apply(lambda x: len(str(x).split()))    \n",
    "new_dataset['min_salary'] = new_dataset[\"salary_range\"].apply(lambda r: int(r.split(\"-\")[0]) if r.split(\"-\")[0].isnumeric() else -1 if \"-\" in r else r if r != '' else -1)\n",
    "new_dataset['max_salary'] = new_dataset[\"salary_range\"].apply(get_max)\n",
    "new_dataset['diff_salary'] = new_dataset[\"salary_range\"].apply(get_diff)\n",
    "\n",
    "new_location_dict = Dictionary()\n",
    "new_dataset['loc_ids'] = new_dataset['location'].apply(new_location_dict.add_to_dict)\n",
    "new_department_dict = Dictionary()\n",
    "new_dataset['dep_ids'] = new_dataset['department'].apply(new_department_dict.add_to_dict)\n",
    "new_employment_type_dict = Dictionary()\n",
    "new_dataset['emptype_ids'] = new_dataset['employment_type'].apply(new_employment_type_dict.add_to_dict)\n",
    "new_required_experience_dict = Dictionary()\n",
    "new_dataset['reqexp_ids'] = new_dataset['required_experience'].apply(new_required_experience_dict.add_to_dict)\n",
    "new_required_education_dict = Dictionary()\n",
    "new_dataset['reqedu_ids'] = new_dataset['required_education'].apply(new_required_education_dict.add_to_dict)\n",
    "new_industry_dict = Dictionary()\n",
    "new_dataset['ind_ids'] = new_dataset['industry'].apply(new_industry_dict.add_to_dict)\n",
    "new_function_dict = Dictionary()\n",
    "new_dataset['func_ids'] = new_dataset['function'].apply(new_function_dict.add_to_dict)\n",
    "\n",
    "new_feat_train = new_dataset[\n",
    "    feats_desc + feats_title + feats_cp +\n",
    "    feats_ben + feats_req + feats_bin +\n",
    "    feats_salary + reptext_feat\n",
    "]\n",
    "\n",
    "new_feat_train.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "       len_desc  len_char_desc  len_word_desc  len_title  len_char_title  \\\n13832       961             39            143         18              10   \n17723      2712             74            362         78              24   \n17610       431             61             60         40              22   \n17774       926             60            124          8               7   \n5434        110             25             17         22              13   \n\n       len_word_title  len_cp  len_char_cp  len_word_cp  len_ben  ...  \\\n13832               2    1126           51          172        0  ...   \n17723              12     624           53           95        0  ...   \n17610               7       0            0            0        0  ...   \n17774               1       0            0            0      182  ...   \n5434                3       0            0            0        0  ...   \n\n       min_salary  max_salary  diff_salary  loc_ids  dep_ids  emptype_ids  \\\n13832          -1          -1           -1        0        0            0   \n17723          -1          -1           -1        1        1            1   \n17610          -1          -1           -1        2        0            2   \n17774          -1          -1           -1        3        0            0   \n5434           -1          -1           -1        4        1            3   \n\n       reqexp_ids  reqedu_ids  ind_ids  func_ids  \n13832           0           0        0         0  \n17723           0           0        1         1  \n17610           0           0        1         0  \n17774           0           0        2         2  \n5434            0           0        1         0  \n\n[5 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>len_desc</th>\n      <th>len_char_desc</th>\n      <th>len_word_desc</th>\n      <th>len_title</th>\n      <th>len_char_title</th>\n      <th>len_word_title</th>\n      <th>len_cp</th>\n      <th>len_char_cp</th>\n      <th>len_word_cp</th>\n      <th>len_ben</th>\n      <th>...</th>\n      <th>min_salary</th>\n      <th>max_salary</th>\n      <th>diff_salary</th>\n      <th>loc_ids</th>\n      <th>dep_ids</th>\n      <th>emptype_ids</th>\n      <th>reqexp_ids</th>\n      <th>reqedu_ids</th>\n      <th>ind_ids</th>\n      <th>func_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13832</th>\n      <td>961</td>\n      <td>39</td>\n      <td>143</td>\n      <td>18</td>\n      <td>10</td>\n      <td>2</td>\n      <td>1126</td>\n      <td>51</td>\n      <td>172</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17723</th>\n      <td>2712</td>\n      <td>74</td>\n      <td>362</td>\n      <td>78</td>\n      <td>24</td>\n      <td>12</td>\n      <td>624</td>\n      <td>53</td>\n      <td>95</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17610</th>\n      <td>431</td>\n      <td>61</td>\n      <td>60</td>\n      <td>40</td>\n      <td>22</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17774</th>\n      <td>926</td>\n      <td>60</td>\n      <td>124</td>\n      <td>8</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>182</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5434</th>\n      <td>110</td>\n      <td>25</td>\n      <td>17</td>\n      <td>22</td>\n      <td>13</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 31
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. SGD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  SGD\n",
      "Accuracy:  0.6736596736596736\n",
      "Precision:  0.5074626865671642\n",
      "Recall:  0.4788732394366197\n",
      "F1-Measure:  0.4927536231884058\n",
      "Execution time: 0.02126288414001465\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sgd = SGDClassifier(n_jobs=12, loss='hinge', max_iter=50000)\n",
    "evaluation(sgd, \"SGD\", new_feat_train, new_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  SVC\n",
      "Accuracy:  0.6841491841491841\n",
      "Precision:  1.0\n",
      "Recall:  0.045774647887323945\n",
      "F1-Measure:  0.08754208754208755\n",
      "Execution time: 0.05649685859680176\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "evaluation(svc, \"SVC\", new_feat_train, new_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. DecissionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  Decision Tree Classifier\n",
      "Accuracy:  0.837995337995338\n",
      "Precision:  0.7375415282392026\n",
      "Recall:  0.7872340425531915\n",
      "F1-Measure:  0.7615780445969125\n",
      "Execution time: 0.004677534103393555\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier()\n",
    "evaluation(dc, \"Decision Tree Classifier\", new_feat_train, new_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Bagging Classifier \n",
    "\n",
    "using 20 DecissionTress"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  Bagging Classifier\n",
      "Accuracy:  0.9032634032634033\n",
      "Precision:  0.868421052631579\n",
      "Recall:  0.8279569892473119\n",
      "F1-Measure:  0.8477064220183487\n",
      "Execution time: 0.03319597244262695\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=1.0, n_estimators=20)\n",
    "evaluation(bagging, \"Bagging Classifier\", new_feat_train, new_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Voting Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  Voting Classifier\n",
      "Accuracy:  0.7424242424242424\n",
      "Precision:  0.8488372093023255\n",
      "Recall:  0.2597864768683274\n",
      "F1-Measure:  0.3978201634877384\n",
      "Execution time: 0.06292486190795898\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sgd = SGDClassifier(n_jobs=12, loss='hinge', max_iter=50000)\n",
    "svc = SVC(kernel='rbf', gamma='auto')\n",
    "dc = DecisionTreeClassifier()\n",
    "\n",
    "voting = VotingClassifier(estimators=[('sgd',sgd),('svc',svc),('dc',dc)], voting='hard')\n",
    "evaluation(voting, \"Voting Classifier\", new_feat_train, new_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6. Random Forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifier:  Random Forest\n",
      "Accuracy:  0.9102564102564102\n",
      "Precision:  0.8736462093862816\n",
      "Recall:  0.852112676056338\n",
      "F1-Measure:  0.8627450980392156\n",
      "Execution time: 0.20832419395446777\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=660, n_jobs=4)\n",
    "evaluation(rf, \"Random Forest\", new_feat_train, new_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## THE END\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}